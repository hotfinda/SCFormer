{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0153594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import models\n",
    "import ops.trains as trains\n",
    "import ops.tests as tests\n",
    "import ops.datasets as datasets\n",
    "import ops.schedulers as schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"%s/configs/imagenet_vit.yaml\"\n",
    "with open(config_path) as f:\n",
    "    args = yaml.load(f)\n",
    "    \n",
    "dataset_args = copy.deepcopy(args).get(\"dataset\")\n",
    "train_args = copy.deepcopy(args).get(\"train\")\n",
    "val_args = copy.deepcopy(args).get(\"val\")\n",
    "model_args = copy.deepcopy(args).get(\"model\")\n",
    "optim_args = copy.deepcopy(args).get(\"optim\")\n",
    "env_args = copy.deepcopy(args).get(\"env\")\n",
    "\n",
    "\n",
    "dataset_train, dataset_test = datasets.get_dataset(**dataset_args, download=True)\n",
    "dataset_name = dataset_args[\"name\"]\n",
    "num_classes = len(dataset_train.classes)\n",
    "\n",
    "dataset_train = DataLoader(dataset_train, \n",
    "                           shuffle=True, \n",
    "                           num_workers=train_args.get(\"num_workers\", 4), \n",
    "                           batch_size=train_args.get(\"batch_size\", 128))\n",
    "dataset_test = DataLoader(dataset_test, \n",
    "                          num_workers=val_args.get(\"num_workers\", 4), \n",
    "                          batch_size=val_args.get(\"batch_size\", 128))\n",
    "\n",
    "print(\"Train: %s, Test: %s, Classes: %s\" % (\n",
    "    len(dataset_train.dataset), \n",
    "    len(dataset_test.dataset), \n",
    "    num_classes\n",
    "))\n",
    "\n",
    "\n",
    "name = \"daa_50\"\n",
    "\n",
    "\n",
    "model = models.get_model(name, num_classes=num_classes)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = os.path.join(\"runs\", dataset_name, model.name, current_time)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "with open(\"%s/config.yaml\" % log_dir, \"w\") as f:\n",
    "    yaml.dump(args, f)\n",
    "with open(\"%s/model.log\" % log_dir, \"w\") as f:\n",
    "    f.write(repr(model))\n",
    "\n",
    "print(\"Create TensorBoard log dir: \", log_dir)\n",
    "\n",
    "\n",
    "\n",
    "gpu = torch.cuda.is_available()\n",
    "optimizer, train_scheduler = trains.get_optimizer(model, **optim_args)\n",
    "warmup_scheduler = schedulers.WarmupScheduler(optimizer, len(dataset_train) * train_args.get(\"warmup_epochs\", 0))\n",
    "\n",
    "trains.train(model, optimizer,\n",
    "             dataset_train, dataset_test,\n",
    "             train_scheduler, warmup_scheduler,\n",
    "             train_args, val_args, gpu,\n",
    "             writer, \n",
    "             snapshot=-1, dataset_name=dataset_name, uid=current_time)  # Set `snapshot=N` to save snapshots every N epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
